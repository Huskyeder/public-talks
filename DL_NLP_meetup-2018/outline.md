# DL + NLP

Audience:
 
 - Technical-ish
 - Learning DL
 - Probably learning NLP
 - Probably have coding experience

Talk:

 - Other lighting talks on same night
 - 45 minutes, w/ Q+A
 - Will include Spoilers example
 
## Intro

 - What is NLP?
 - Why DL + NLP
 - Why now?

## Token based

 - Tokenization / preprocessing
   - Padding / max sequence length
 - Architectures  
   - Word2Vec / Embeddings
     - Vocabulary
     - UNK token strategies
   - Convolutional
   - RNN (LSTM / GRU)
   - Output
 - Frameworks
   - TorchText
   - Keras (1D / time series)

## Character based

1 slide, w/ synonyms to token based

 - Echoing approaches from token based
 - Tokenization / preprocessing: Divide into character set
 - Embedding: Per character
 - Architecture
   - Convolution: More important
   - RNN (Longer to train)

## Case study: Spoilers

 - Context
 - Preprocessing
 - Architectures
 - Results

## Wrap up

 - Token based
 - Character based
 - Case study

## Thank you, Q+A

## Resources

 - Yoav Goldberg
 - Deep Learning Book